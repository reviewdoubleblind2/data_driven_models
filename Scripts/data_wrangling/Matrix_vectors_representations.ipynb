{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this notebook\n",
    "\n",
    "This notebook is used to generate the tfidf for all the datasets for RF and also the sequence tokens for CNN and RNN\n",
    "\n",
    "**The notebook must be in the same folder as the results of op5 and quartiles notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from random import shuffle\n",
    "from collections import namedtuple\n",
    "import collections\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOW matrix \n",
    "MatrixX = namedtuple('MatrixX', 'train val test') # BOW ( it can be: count, tf,idf, binary)\n",
    "\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "representations = ['b0','b1','b1_int','b1_iden','b1_int_iden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach = 'binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"Sequence_tokens\")\n",
    "except OSError:\n",
    "    print (\"Creation of the directory \\Sequence_tokens failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matrix(train, val, test, token_obj,mode):\n",
    "    \n",
    "    mtr_train = token_obj.texts_to_matrix(train,mode = mode)\n",
    "    mtr_val = token_obj.texts_to_matrix(val,mode = mode)\n",
    "    mtr_test = token_obj.texts_to_matrix(test,mode = mode)     \n",
    "    \n",
    "    return (mtr_train, mtr_val,mtr_test)\n",
    "\n",
    "def save_matrix(named_tuple,dataset,mode = None,rep='binary',folder=None, approach= 'binary' ):\n",
    "    print(approach)\n",
    "    for name, data in named_tuple._asdict().items():\n",
    "        \n",
    "        if folder is None:\n",
    "            name = f'BOW/{approach}_{dataset}_{mode}_{name}_{rep}.npy'    \n",
    "        else:\n",
    "            name = f'{folder}/{approach}_{dataset}_{name}_{rep}.npy'    \n",
    "            \n",
    "        np.save(name, data) \n",
    "        \n",
    "def generate_matrix_rep(token_obj, train, val, test,representations, mode):\n",
    "    \n",
    "    matrix_modes_list = collections.defaultdict(list) \n",
    "    train = train\n",
    "    test = test\n",
    "    val = val\n",
    "    \n",
    "        \n",
    "    for rep in representations:\n",
    "        text_train = train['0']\n",
    "        text_test = test['0']\n",
    "        text_val = val['0']\n",
    "        \n",
    "        \n",
    "        bow_train_bn, bow_val_bn, bow_test_bn = generate_matrix(text_train, text_val, text_test,token_obj,mode)\n",
    "        \n",
    "        matrix_modes_list['rep'].append(bow_train_bn)\n",
    "        matrix_modes_list['rep'].append(bow_val_bn)\n",
    "        matrix_modes_list['rep'].append(bow_test_bn) \n",
    "        \n",
    "    bn_train = MatrixX(*matrix_modes_list['rep'])\n",
    "    \n",
    "    return (bn_train)\n",
    "\n",
    "def generate_token_texts(dataset, rep, tokenizer, x_train, x_val, x_test,approach):\n",
    "    \n",
    "    temp = pd.read_csv(f'{approach}_{rep}_{dataset}.csv',usecols= ['LEN'])\n",
    "    max_lenght = np.max(temp.values)\n",
    "    \n",
    "    train_tokens= tokenizer.texts_to_sequences(x_train['0'])\n",
    "    val_tokens= tokenizer.texts_to_sequences(x_val['0'])\n",
    "    test_tokens= tokenizer.texts_to_sequences(x_test['0'])\n",
    "    \n",
    "    train_tokens = pad_sequences(train_tokens, maxlen= max_lenght, padding='post')\n",
    "    val_tokens = pad_sequences(val_tokens, maxlen= max_lenght, padding='post')\n",
    "    test_tokens = pad_sequences(test_tokens, maxlen= max_lenght, padding='post')\n",
    "    print(\"shape tarin tokens\",train_tokens.shape)\n",
    "    print(\"shape val tokens\",val_tokens.shape)\n",
    "    print(\"shape test tokens\",test_tokens.shape)\n",
    "    \n",
    "    \n",
    "    resp = MatrixX(train_tokens, val_tokens, test_tokens)\n",
    "    \n",
    "    return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate matrix for each dataset and representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Russell matrix\n",
    "rep = 'b1_int_iden'\n",
    "dataset = 'Russell'\n",
    "mode = 'tfidf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b1_int_iden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'Tokenizer/{approach}_{dataset}_{rep}.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "x_train = pd.read_csv(f'Data_train_test/{approach}_Xtrain_{dataset}_{rep}.csv')\n",
    "x_val = pd.read_csv(f'Data_train_test/{approach}_Xval_{dataset}_{rep}.csv')\n",
    "x_test = pd.read_csv(f'Data_train_test/{approach}_Xtest_{dataset}_{rep}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_b0 = generate_matrix_rep(tokenizer, x_train, x_val, x_test, [rep],mode)\n",
    "\n",
    "save_matrix(tuple_b0,dataset,mode= mode,rep=rep,approach= approach)\n",
    "tuple_b0.train.shape, tuple_b0.test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_texts = generate_token_texts(dataset, rep, tokenizer, x_train, x_val, x_test,approach)\n",
    "save_matrix(tuple_texts, dataset, mode, rep, folder = 'Sequence_tokens',approach=approach)\n",
    "tuple_texts.train.shape, tuple_texts.val.shape, tuple_texts.test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b1_iden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Russell matrix\n",
    "rep = 'b1_iden'\n",
    "\n",
    "with open(f'Tokenizer/{approach}_{dataset}_{rep}.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "x_train = pd.read_csv(f'Data_train_test/{approach}_Xtrain_{dataset}_{rep}.csv')\n",
    "x_val = pd.read_csv(f'Data_train_test/{approach}_Xval_{dataset}_{rep}.csv')\n",
    "x_test = pd.read_csv(f'Data_train_test/{approach}_Xtest_{dataset}_{rep}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_b0 = generate_matrix_rep(tokenizer, x_train, x_val, x_test, [rep],mode)\n",
    "save_matrix(tuple_b0,dataset,mode= mode,rep=rep,approach= approach)\n",
    "tuple_b0.train.shape, tuple_b0.test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_texts = generate_token_texts(dataset, rep, tokenizer, x_train, x_val, x_test,approach)\n",
    "save_matrix(tuple_texts, dataset, mode, rep, folder = 'Sequence_tokens',approach= approach)\n",
    "tuple_texts.train.shape, tuple_texts.test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b1_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Russell matrix\n",
    "rep = 'b1_int'\n",
    "with open(f'Tokenizer/{approach}_{dataset}_{rep}.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "x_train = pd.read_csv(f'Data_train_test/{approach}_Xtrain_{dataset}_{rep}.csv')\n",
    "x_val = pd.read_csv(f'Data_train_test/{approach}_Xval_{dataset}_{rep}.csv')\n",
    "x_test = pd.read_csv(f'Data_train_test/{approach}_Xtest_{dataset}_{rep}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_b0 = generate_matrix_rep(tokenizer, x_train, x_val, x_test, [rep],mode)\n",
    "save_matrix(tuple_b0,dataset,mode= mode,rep=rep,approach= approach)\n",
    "tuple_b0.train.shape, tuple_b0.test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_texts = generate_token_texts(dataset, rep, tokenizer, x_train, x_val, x_test,approach)\n",
    "save_matrix(tuple_texts, dataset, mode, rep, folder = 'Sequence_tokens',approach= approach)\n",
    "tuple_texts.train.shape, tuple_texts.test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Russell matrix\n",
    "rep = 'b1'\n",
    "with open(f'Tokenizer/{approach}_{dataset}_{rep}.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)    \n",
    "    \n",
    "x_train = pd.read_csv(f'Data_train_test/{approach}_Xtrain_{dataset}_{rep}.csv')\n",
    "x_val = pd.read_csv(f'Data_train_test/{approach}_Xval_{dataset}_{rep}.csv')\n",
    "x_test = pd.read_csv(f'Data_train_test/{approach}_Xtest_{dataset}_{rep}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_b0 = generate_matrix_rep(tokenizer, x_train, x_val, x_test, [rep],mode)\n",
    "save_matrix(tuple_b0,dataset,mode= mode,rep=rep,approach= approach)\n",
    "tuple_b0.train.shape, tuple_b0.test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_texts = generate_token_texts(dataset, rep, tokenizer, x_train, x_val, x_test,approach)\n",
    "save_matrix(tuple_texts, dataset, mode, rep, folder = 'Sequence_tokens',approach= approach)\n",
    "tuple_texts.train.shape, tuple_texts.test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Russell matrix\n",
    "rep = 'b0'\n",
    "with open(f'Tokenizer/{approach}_{dataset}_{rep}.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)    \n",
    "    \n",
    "x_train = pd.read_csv(f'Data_train_test/{approach}_Xtrain_{dataset}_{rep}.csv')\n",
    "x_val = pd.read_csv(f'Data_train_test/{approach}_Xval_{dataset}_{rep}.csv')\n",
    "x_test = pd.read_csv(f'Data_train_test/{approach}_Xtest_{dataset}_{rep}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_b0 = generate_matrix_rep(tokenizer, x_train, x_val, x_test, [rep],mode)\n",
    "save_matrix(tuple_b0,dataset,mode= mode,rep=rep,approach= approach)\n",
    "tuple_b0.train.shape, tuple_b0.test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_texts = generate_token_texts(dataset, rep, tokenizer, x_train, x_val, x_test,approach)\n",
    "save_matrix(tuple_texts, dataset, mode, rep, folder = 'Sequence_tokens',approach= approach)\n",
    "tuple_texts.train.shape, tuple_texts.test.shape"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
